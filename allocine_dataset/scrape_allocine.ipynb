{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ROOT_URL = \"http://www.allocine.fr\"\n",
    "URL_FILE = 'allocine_films_urls.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Films URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% (7553/7553) [#########] eta 00:01 |\r"
     ]
    }
   ],
   "source": [
    "from allocine_scraper import get_film_urls\n",
    "\n",
    "urls = get_film_urls(ROOT_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: this will overwrite the url file\n",
    "with open(URL_FILE, 'w') as f:\n",
    "    for url in urls:\n",
    "        f.write(\"{}\\n\".format(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113291\n"
     ]
    }
   ],
   "source": [
    "urls = []\n",
    "with open(URL_FILE, 'r') as f:\n",
    "    urls = f.read().splitlines()\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap Films from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [\n",
    "    # The first films are very popular\n",
    "    urls[0:1000], # 0\n",
    "    urls[1000:2000], # 1\n",
    "    urls[2000:3000], # 2\n",
    "    urls[3000:4000], # 3\n",
    "    urls[4000:5000], # 4\n",
    "    urls[5000:6000], # 5\n",
    "    urls[6000:7000], # 6\n",
    "    urls[7000:8000], # 7\n",
    "    urls[8000:9000], # 8\n",
    "    urls[9000:10000], # 9 \n",
    "    urls[10000:20000], # 10\n",
    "    urls[20000:30000], # 11\n",
    "    urls[30000:40000], # 12\n",
    "    urls[40000:50000], # 13\n",
    "    urls[50000:60000], # 14\n",
    "    urls[60000:70000], # 15\n",
    "    urls[70000:80000], # 16\n",
    "    urls[80000:90000], # 17\n",
    "    urls[90000:100000], # 18\n",
    "    urls[100000:110000], # 19\n",
    "    urls[110000:120000], # 20\n",
    "    urls[120000:130000], # 21\n",
    "    urls[130000:], # 22\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/23\n",
      "Batch 2/23\n",
      "Batch 3/23\n",
      "Batch 4/23\n",
      "Batch 5/23\n",
      "Batch 6/23\n",
      "Batch 7/23\n",
      "Batch 8/23\n",
      "Batch 9/23\n",
      "Batch 10/23\n",
      "Error: film-url: http://www.allocine.fr/film/fichefilm-253393/critiques/spectateurs\n",
      "100% (1000/1000) [#########] eta 00:01 |\n",
      "Batch 11/23\n",
      " 32% ( 3210/10000) [#    ] eta 2:13:43 -\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from allocine_scraper import get_film_reviews\n",
    "\n",
    "OUTPUT_PATH = \"pickle\"\n",
    "MAX_REVIEWS_PER_FILM = 30\n",
    "\n",
    "for i, batch_urls in enumerate(batches):    \n",
    "    print(\"Batch {}/{}\".format(i+1, len(batches)))\n",
    "    if i <= 8:\n",
    "        continue        \n",
    "    # Determine pickle file name\n",
    "    out_file = \"allocine_{}.pickle\".format(i)\n",
    "    out_path = os.path.join(OUTPUT_PATH, out_file)\n",
    "    \n",
    "    dic = get_film_reviews(ROOT_URL, batch_urls, MAX_REVIEWS_PER_FILM)\n",
    "    print()\n",
    "    \n",
    "    # Create a pandas DataFrame and save it to disk\n",
    "    df = pd.DataFrame.from_dict(dic)\n",
    "    df.to_pickle(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
