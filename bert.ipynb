{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# better display of review text in dataframes\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "\n",
    "# Seaborn options\n",
    "sns.set(style=\"whitegrid\", font_scale=1.4)\n",
    "\n",
    "# Auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "PICKLE_PATH = \"allocine_dataset/data/allocine_dataset.pickle\"\n",
    "\n",
    "with open(PICKLE_PATH, 'rb') as reader:\n",
    "    data = pickle.load(reader)\n",
    "\n",
    "# Reviews need to be tokenized\n",
    "train_reviews = np.array(data[\"train_set\"]['review'])\n",
    "val_reviews = np.array(data[\"val_set\"]['review'])\n",
    "test_reviews = np.array(data[\"test_set\"]['review'])\n",
    "\n",
    "train_labels = data[\"train_set\"]['polarity']\n",
    "val_labels = data[\"val_set\"]['polarity']\n",
    "test_labels = data[\"test_set\"]['polarity']\n",
    "class_names = data['class_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = train_reviews[:1000]\n",
    "val_reviews = val_reviews[:1000]\n",
    "test_reviews = test_reviews[:1000]\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "val_labels = val_labels[:1000]\n",
    "test_labels = test_labels[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer\n",
    "\n",
    "model_name = \"camembert-base\"\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Si vous cherchez du cinéma abrutissant à tous les étages,n\\'ayant aucune peur du cliché en castagnettes et moralement douteux,\"From Paris with love\" est fait pour vous.Toutes les productions Besson,via sa filière EuropaCorp ont de quoi faire naître la moquerie.Paris y est encore une fois montrée comme une capitale exotique,mais attention si l\\'on se dirige vers la banlieue,on y trouve tout plein d\\'intégristes musulmans prêts à faire sauter le caisson d\\'une ambassadrice américaine.Nauséeux.Alors on se dit qu\\'on va au moins pouvoir apprécier la déconnade d\\'un classique buddy-movie avec le jeune agent aux dents longues obligé de faire équipe avec un vieux lou complètement timbré.Mais d\\'un côté,on a un Jonathan Rhys-meyers fayot au possible,et de l\\'autre un John Travolta en total délire narcissico-badass,crâne rasé et bouc proéminent à l\\'appui.Sinon,il n\\'y a aucun scénario.Seulement,des poursuites débiles sur l\\'autoroute,Travolta qui étale 10 mecs à l\\'arme blanche en 8 mouvements(!!)ou laisse son associé se faire démolir la tronche pendant qu\\'il scrute à la jumelle.Ca pourrait être un plaisir coupable,tellement c\\'est \"hénaurme\",c\\'est juste de la daube dans la droite lignée d\\'un \"Transporteur\",\"Taken\"ou \"Banlieue 13\".'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_review = train_reviews[0]\n",
    "some_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Si',\n",
       " '▁vous',\n",
       " '▁cherchez',\n",
       " '▁du',\n",
       " '▁cinéma',\n",
       " '▁abruti',\n",
       " 'ssant',\n",
       " '▁à',\n",
       " '▁tous',\n",
       " '▁les',\n",
       " '▁étages',\n",
       " ',',\n",
       " 'n',\n",
       " \"'\",\n",
       " 'ayant']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(some_review)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 168, 39, 3162, 25, 1545, 29470, 2927, 15, 117, 19, 9339, 7, 255, 11]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(some_review)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Si vous cherchez du cinéma abrutissant à tous les étages,n\\'ayant aucune peur du cliché en castagnettes et moralement douteux,\"From Paris with love\" est fait pour vous.Toutes les productions Besson,via sa filière EuropaCorp ont de quoi faire naître la moquerie.Paris y est encore une fois montrée comme une capitale exotique,mais attention si l\\'on se dirige vers la banlieue,on y trouve tout plein d\\'intégristes musulmans prêts à faire sauter le caisson d\\'une ambassadrice américaine.Nauséeux.Alors on se dit qu\\'on va au moins pouvoir apprécier la déconnade d\\'un classique buddy-movie avec le jeune agent aux dents longues obligé de faire équipe avec un vieux lou complètement timbré.Mais d\\'un côté,on a un Jonathan Rhys-meyers fayot au possible,et de l\\'autre un John Travolta en total délire narcissico-badass,crâne rasé et bouc proéminent à l\\'appui.Sinon,il n\\'y a aucun scénario.Seulement,des poursuites débiles sur l\\'autoroute,Travolta qui étale 10 mecs à l\\'arme blanche en 8 mouvements(!!)ou laisse son associé se faire démolir la tronche pendant qu\\'il scrute à la jumelle.Ca pourrait être un plaisir coupable,tellement c\\'est \"hénaurme\",c\\'est juste de la daube dans la droite lignée d\\'un \"Transporteur\",\"Taken\"ou \"Banlieue 13\".</s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(some_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 126.2\n",
      "Max length: 512\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_len = [len(tokenizer.encode(review, max_length=512))\n",
    "                          for review in train_reviews]\n",
    "print(\"Average length: {:.1f}\".format(np.mean(reviews_len)))\n",
    "print(\"Max length: {}\".format(max(reviews_len)))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = sns.distplot(reviews_len, bins=150, kde=False, hist_kws=dict(alpha=0.8))\n",
    "ax.set(xlabel='Number of tokens')\n",
    "\n",
    "# Finalize the plot\n",
    "sns.despine(bottom=True)\n",
    "plt.tight_layout(h_pad=2)\n",
    "\n",
    "# Saving plot\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('img/bert/number_of_tokens.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32005"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode_reviews(tokenizer, reviews, max_length):\n",
    "    token_ids = np.zeros(shape=(len(reviews), max_length),\n",
    "                         dtype=np.int32)\n",
    "    for i, review in enumerate(reviews):\n",
    "        encoded = tokenizer.encode(review, max_length=max_length)\n",
    "        token_ids[i, 0:len(encoded)] = encoded\n",
    "    attention_mask = (token_ids != 0).astype(np.int32)\n",
    "    return {\"input_ids\": token_ids, \"attention_mask\": attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 400 # in terms of generated tokens (not words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "encoded_train = encode_reviews(tokenizer, train_reviews, MAX_NB_TOKEN)\n",
    "encoded_valid = encode_reviews(tokenizer, val_reviews, MAX_NB_TOKEN)\n",
    "encoded_test = encode_reviews(tokenizer, test_reviews, MAX_NB_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CamembertPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, tokenizer, max_seq_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def fit(self, X=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        # 1. Tokenize\n",
    "        X_encoded = encode_reviews(self.tokenizer, X, self.max_seq_length)\n",
    "        # 2. Labels\n",
    "        y_array = np.array(y)\n",
    "        return X_encoded, y_array     \n",
    "    \n",
    "    def fit_transform(self, X, y):        \n",
    "        return self.transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFCamembertForSequenceClassification\n",
    "\n",
    "model = TFCamembertForSequenceClassification.from_pretrained(\"jplu/tf-camembert-base\")\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-6, epsilon=1e-08)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)    \n",
    "\n",
    "model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_camembert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "roberta (TFRobertaMainLayer) multiple                  110621952 \n",
      "_________________________________________________________________\n",
      "classifier (TFRobertaClassif multiple                  592130    \n",
      "=================================================================\n",
      "Total params: 111,214,082\n",
      "Trainable params: 111,214,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initial_weights = model.get_weights()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "1000/1000 [==============================] - 121s 121ms/sample - loss: 0.3054 - accuracy: 0.9290 - val_loss: 0.2387 - val_accuracy: 0.9530\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    encoded_train, y_train, epochs=1, batch_size=4, \n",
    "    validation_data=(encoded_valid, y_val), verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy vs Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class EarlyStoppingModel(BaseEstimator):\n",
    "    def __init__(self, transformers_model, max_epoches, batch_size, validation_data):\n",
    "        self.model = transformers_model\n",
    "        self.max_epoches = max_epoches\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_data = validation_data\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Defines early stopper\n",
    "        early_stopper = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', mode='auto', patience=1, # only 1 !\n",
    "            verbose=1, restore_best_weights=True\n",
    "        )        \n",
    "\n",
    "        # Train model on data subset\n",
    "        self.model.fit(\n",
    "            X, y,\n",
    "            validation_data=self.validation_data,\n",
    "            epochs=self.max_epoches, \n",
    "            batch_size=self.batch_size,\n",
    "            callbacks=[early_stopper], \n",
    "            verbose=1\n",
    "        )        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):        \n",
    "        scores = self.model.predict(X)\n",
    "        y_pred = np.argmax(scores, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "def accuracy_vs_training_data(camembert_model, initial_weights, \n",
    "                              preprocessor, sizes,\n",
    "                              train_reviews, train_labels,\n",
    "                              val_reviews, val_labels,\n",
    "                              test_reviews, test_labels):\n",
    "    test_accuracies = []\n",
    "    for size in sizes:        \n",
    "        # Preprocess data\n",
    "        X_train, y_train = preprocessor.fit_transform(\n",
    "            train_reviews[:size], train_labels[:size]\n",
    "        )\n",
    "        X_val, y_val = preprocessor.transform(val_reviews, val_labels)\n",
    "        X_test, y_test = preprocessor.transform(test_reviews, test_labels)\n",
    "        \n",
    "        # Reset weights to initial value\n",
    "        camembert_model.set_weights(initial_weights)\n",
    "        best_model = EarlyStoppingModel(\n",
    "            camembert_model, max_epoches=7, batch_size=4,\n",
    "            validation_data=(X_val, y_val)\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        test_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "        test_accuracies.append(test_acc)\n",
    "        print(\"Test acc: \" + str(test_acc))\n",
    "        \n",
    "    return test_accuracies    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 5000 samples\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_camembert_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_camembert_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "1000/1000 [==============================] - 235s 235ms/sample - loss: 0.6934 - accuracy: 0.5010 - val_loss: 0.6902 - val_accuracy: 0.6686\n",
      "Epoch 2/7\n",
      "1000/1000 [==============================] - 229s 229ms/sample - loss: 0.6876 - accuracy: 0.6110 - val_loss: 0.6832 - val_accuracy: 0.7116\n",
      "Epoch 3/7\n",
      "1000/1000 [==============================] - 229s 229ms/sample - loss: 0.6765 - accuracy: 0.7400 - val_loss: 0.6589 - val_accuracy: 0.8762\n",
      "Epoch 4/7\n",
      "1000/1000 [==============================] - 229s 229ms/sample - loss: 0.6095 - accuracy: 0.8990 - val_loss: 0.4965 - val_accuracy: 0.9348\n",
      "Epoch 5/7\n",
      "1000/1000 [==============================] - 229s 229ms/sample - loss: 0.4448 - accuracy: 0.9250 - val_loss: 0.3447 - val_accuracy: 0.9418\n",
      "Epoch 6/7\n",
      "1000/1000 [==============================] - 229s 229ms/sample - loss: 0.3315 - accuracy: 0.9410 - val_loss: 0.2775 - val_accuracy: 0.9430\n",
      "Epoch 7/7\n",
      "1000/1000 [==============================] - 229s 229ms/sample - loss: 0.2606 - accuracy: 0.9580 - val_loss: 0.2368 - val_accuracy: 0.9440\n",
      "Test acc: 0.9444\n",
      "Train on 2000 samples, validate on 5000 samples\n",
      "Epoch 1/7\n",
      "2000/2000 [==============================] - 319s 160ms/sample - loss: 0.6926 - accuracy: 0.4995 - val_loss: 0.6886 - val_accuracy: 0.5330\n",
      "Epoch 2/7\n",
      "2000/2000 [==============================] - 319s 160ms/sample - loss: 0.6857 - accuracy: 0.6145 - val_loss: 0.6786 - val_accuracy: 0.7426\n",
      "Epoch 3/7\n",
      "2000/2000 [==============================] - 319s 160ms/sample - loss: 0.6666 - accuracy: 0.7675 - val_loss: 0.6343 - val_accuracy: 0.8992\n",
      "Epoch 4/7\n",
      "1532/2000 [=====================>........] - ETA: 48s - loss: 0.5804 - accuracy: 0.8868WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[4,400,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node tf_camembert_for_sequence_classification/roberta/encoder/layer_._11/output/LayerNorm/batchnorm/mul_2 (defined at /home/theophile/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/transformers/modeling_tf_bert.py:338) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Reshape_520/_42]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[4,400,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node tf_camembert_for_sequence_classification/roberta/encoder/layer_._11/output/LayerNorm/batchnorm/mul_2 (defined at /home/theophile/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/transformers/modeling_tf_bert.py:338) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_27660]\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a53331ef8568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_reviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mval_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtest_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-17-6073eb3a61a3>\u001b[0m in \u001b[0;36maccuracy_vs_training_data\u001b[0;34m(camembert_model, initial_weights, preprocessor, sizes, train_reviews, train_labels, val_reviews, val_labels, test_reviews, test_labels)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Evaluate on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8aca33fa203f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         )        \n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[4,400,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node tf_camembert_for_sequence_classification/roberta/encoder/layer_._11/output/LayerNorm/batchnorm/mul_2 (defined at /home/theophile/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/transformers/modeling_tf_bert.py:338) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Reshape_520/_42]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[4,400,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node tf_camembert_for_sequence_classification/roberta/encoder/layer_._11/output/LayerNorm/batchnorm/mul_2 (defined at /home/theophile/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/transformers/modeling_tf_bert.py:338) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_27660]\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "#sizes = [int(p) for p in np.geomspace(1000, 160000, 10)]\n",
    "sizes = [1000, 2000, 3000, 4000, 5000]\n",
    "preprocessor = CamembertPreprocessor(tokenizer, MAX_SEQ_LEN)\n",
    "\n",
    "test_accuracies = accuracy_vs_training_data(\n",
    "    model, initial_weights, \n",
    "    preprocessor, sizes,\n",
    "    train_reviews, train_labels,\n",
    "    val_reviews[:5000], val_labels[:5000],\n",
    "    test_reviews[:5000], test_labels[:5000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFCamembertModel\n",
    "from tensorflow.keras.layers import Dropout, Dense, Activation\n",
    "\n",
    "\n",
    "class ClassificationModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, intent_num_labels=None, model_name=\"jplu/tf-camembert-base\",\n",
    "                 dropout_prob=0.1):\n",
    "        super().__init__(name=\"joint_intent_slot\")\n",
    "        self.bert = TFCamembertModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Classification head\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(dropout_prob)\n",
    "        #self.linear_1 = tf.keras.layers.Dense(768)\n",
    "        #self.activation = tf.keras.layers.Activation('tanh')\n",
    "        #self.dropout_2 = tf.keras.layers.Dropout(dropout_prob)\n",
    "        self.linear_2 = tf.keras.layers.Dense(2)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        sequence_output, pooled_output = self.bert(inputs, **kwargs)\n",
    "\n",
    "        x = self.dropout_1(pooled_output, training=kwargs.get(\"training\", False))        \n",
    "        #x = self.linear_1(x)\n",
    "        #x = self.activation(x)\n",
    "        #x = self.dropout_2(x, training=kwargs.get(\"training\", False))\n",
    "        logits = self.linear_2(x)\n",
    "        return logits\n",
    "\n",
    "# TODO: see https://huggingface.co/transformers/v2.1.1/_modules/transformers/modeling_tf_roberta.html#TFRobertaForSequenceClassification\n",
    "intent_model = ClassificationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)    \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "\n",
    "intent_model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFCamembertForSequenceClassification\n",
    "\n",
    "model = TFCamembertForSequenceClassification.from_pretrained(\"jplu/tf-camembert-base\")\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)    \n",
    "\n",
    "model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_for_sequence_classification_4/roberta/pooler/dense/kernel:0', 'tf_camembert_for_sequence_classification_4/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_for_sequence_classification_4/roberta/pooler/dense/kernel:0', 'tf_camembert_for_sequence_classification_4/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "12000/12000 [==============================] - 569s 47ms/sample - loss: 0.2662 - accuracy: 0.8785 - val_loss: 0.1659 - val_accuracy: 0.9366\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 571s 48ms/sample - loss: 0.1176 - accuracy: 0.9565 - val_loss: 0.1431 - val_accuracy: 0.9489\n",
      "Epoch 3/10\n",
      " 1184/12000 [=>............................] - ETA: 7:47 - loss: 0.0858 - accuracy: 0.9707"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-7de3361d8584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(\n\u001b[1;32m      2\u001b[0m     \u001b[0mencoded_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Trained with max length = 200, val_accuracy = 0.9489 after 2 epochs\n",
    "history = model.fit(\n",
    "    encoded_train, y_train, epochs=10, batch_size=8, \n",
    "    validation_data=(encoded_valid, y_val), verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 4000 samples\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_camembert_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "12000/12000 [==============================] - 1634s 136ms/sample - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "12000/12000 [==============================] - 1631s 136ms/sample - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6969 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "12000/12000 [==============================] - 1635s 136ms/sample - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6967 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "12000/12000 [==============================] - 1637s 136ms/sample - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "12000/12000 [==============================] - 1638s 137ms/sample - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "12000/12000 [==============================] - 1638s 136ms/sample - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "12000/12000 [==============================] - 1638s 136ms/sample - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "12000/12000 [==============================] - 1637s 136ms/sample - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "12000/12000 [==============================] - 1637s 136ms/sample - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "10185/12000 [========================>.....] - ETA: 3:43 - loss: 0.6932 - accuracy: 0.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-741e4ae6e0f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(\n\u001b[1;32m      2\u001b[0m     \u001b[0mencoded_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    encoded_train, y_train, epochs=30, batch_size=3, \n",
    "    validation_data=(encoded_valid, y_val), verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
