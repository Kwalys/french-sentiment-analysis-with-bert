{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# better display of review text in dataframes\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "\n",
    "# Seaborn options\n",
    "sns.set(style=\"whitegrid\", font_scale=1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "PICKLE_PATH = \"allocine_dataset/data/allocine_dataset.pickle\"\n",
    "\n",
    "with open(PICKLE_PATH, 'rb') as reader:\n",
    "    data = pickle.load(reader)\n",
    "\n",
    "# Reviews need to be tokenized\n",
    "train_reviews = np.array(data[\"train_set\"]['review'])\n",
    "val_reviews = np.array(data[\"val_set\"]['review'])\n",
    "test_reviews = np.array(data[\"test_set\"]['review'])\n",
    "all_reviews = np.concatenate((train_reviews, val_reviews, test_reviews), axis=0)\n",
    "\n",
    "y_train = np.array(data[\"train_set\"]['polarity'])\n",
    "y_val = np.array(data[\"val_set\"]['polarity'])\n",
    "y_test = np.array(data[\"test_set\"]['polarity'])\n",
    "class_names = data['class_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = train_reviews[:3000]\n",
    "val_reviews = val_reviews[:3000]\n",
    "y_train = y_train[:3000]\n",
    "y_val = y_val[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer\n",
    "\n",
    "model_name = \"camembert-base\"\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gros déception ! Je ne comprends pas pourquoi adapter un livre si pour ne pas en tenir compte. Le côté \"histoire\" n\\'est pas exploité, la fin n\\'a plus rien avoir avec le livre... Ils nous avaient déjà gâcher la fin d\\'anges & demons, mais la vraiment on se demande pourquoi cette adaptation. Fan du livre passez votre chemin'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_review = train_reviews[2]\n",
    "some_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Gros',\n",
       " '▁déception',\n",
       " '▁!',\n",
       " '▁Je',\n",
       " '▁ne',\n",
       " '▁comprends',\n",
       " '▁pas',\n",
       " '▁pourquoi',\n",
       " '▁adapter',\n",
       " '▁un',\n",
       " '▁livre',\n",
       " '▁si',\n",
       " '▁pour',\n",
       " '▁ne',\n",
       " '▁pas',\n",
       " '▁en',\n",
       " '▁tenir',\n",
       " '▁compte',\n",
       " '.',\n",
       " '▁Le',\n",
       " '▁côté',\n",
       " '▁\"',\n",
       " 'histoire',\n",
       " '\"',\n",
       " '▁n',\n",
       " \"'\",\n",
       " 'est',\n",
       " '▁pas',\n",
       " '▁exploité',\n",
       " ',',\n",
       " '▁la',\n",
       " '▁fin',\n",
       " '▁n',\n",
       " \"'\",\n",
       " 'a',\n",
       " '▁plus',\n",
       " '▁rien',\n",
       " '▁avoir',\n",
       " '▁avec',\n",
       " '▁le',\n",
       " '▁livre',\n",
       " '...',\n",
       " '▁Ils',\n",
       " '▁nous',\n",
       " '▁avaient',\n",
       " '▁déjà',\n",
       " '▁gâcher',\n",
       " '▁la',\n",
       " '▁fin',\n",
       " '▁d',\n",
       " \"'\",\n",
       " 'ange',\n",
       " 's',\n",
       " '▁&',\n",
       " '▁de',\n",
       " 'mons',\n",
       " ',',\n",
       " '▁mais',\n",
       " '▁la',\n",
       " '▁vraiment',\n",
       " '▁on',\n",
       " '▁se',\n",
       " '▁demande',\n",
       " '▁pourquoi',\n",
       " '▁cette',\n",
       " '▁adaptation',\n",
       " '.',\n",
       " '▁Fan',\n",
       " '▁du',\n",
       " '▁livre',\n",
       " '▁passez',\n",
       " '▁votre',\n",
       " '▁chemin']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(some_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 5507,\n",
       " 10480,\n",
       " 83,\n",
       " 100,\n",
       " 45,\n",
       " 4312,\n",
       " 34,\n",
       " 590,\n",
       " 9426,\n",
       " 23,\n",
       " 510,\n",
       " 86,\n",
       " 24,\n",
       " 45,\n",
       " 34,\n",
       " 22,\n",
       " 1852,\n",
       " 287,\n",
       " 9,\n",
       " 54,\n",
       " 423,\n",
       " 87,\n",
       " 549,\n",
       " 130,\n",
       " 49,\n",
       " 11,\n",
       " 41,\n",
       " 34,\n",
       " 15130,\n",
       " 7,\n",
       " 13,\n",
       " 259,\n",
       " 49,\n",
       " 11,\n",
       " 55,\n",
       " 40,\n",
       " 254,\n",
       " 190,\n",
       " 42,\n",
       " 16,\n",
       " 510,\n",
       " 57,\n",
       " 436,\n",
       " 63,\n",
       " 917,\n",
       " 235,\n",
       " 24064,\n",
       " 13,\n",
       " 259,\n",
       " 18,\n",
       " 11,\n",
       " 4104,\n",
       " 10,\n",
       " 537,\n",
       " 8,\n",
       " 13990,\n",
       " 7,\n",
       " 65,\n",
       " 13,\n",
       " 302,\n",
       " 91,\n",
       " 48,\n",
       " 400,\n",
       " 590,\n",
       " 78,\n",
       " 7696,\n",
       " 9,\n",
       " 10772,\n",
       " 25,\n",
       " 510,\n",
       " 9797,\n",
       " 75,\n",
       " 1111,\n",
       " 6]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(some_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Gros déception! Je ne comprends pas pourquoi adapter un livre si pour ne pas en tenir compte. Le côté \"histoire\" n\\'est pas exploité, la fin n\\'a plus rien avoir avec le livre... Ils nous avaient déjà gâcher la fin d\\'anges & demons, mais la vraiment on se demande pourquoi cette adaptation. Fan du livre passez votre chemin</s>'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(some_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_sequence_lengths = [len(tokenizer.encode(text, max_length=200))\n",
    "                          for text in train_reviews]\n",
    "plt.hist(train_sequence_lengths, bins=30)\n",
    "plt.title(f\"max sequence length: {max(train_sequence_lengths)}\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32005"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_val = tf.keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    5,    87,   243, ...,    33,    17,     6],\n",
       "       [    5,  5897,    49, ...,  7490,     9,     6],\n",
       "       [    5,  5507, 10480, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [    5,  5326,  2534, ...,     0,     0,     0],\n",
       "       [    5,  5897,     8, ...,     0,     0,     0],\n",
       "       [    5,   746,   221, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode_dataset(tokenizer, text_sequences, max_length):\n",
    "    token_ids = np.zeros(shape=(len(text_sequences), max_length),\n",
    "                         dtype=np.int32)\n",
    "    for i, text_sequence in enumerate(text_sequences):\n",
    "        encoded = tokenizer.encode(text_sequence, max_length=max_length)\n",
    "        token_ids[i, 0:len(encoded)] = encoded\n",
    "    attention_masks = (token_ids != 0).astype(np.int32)\n",
    "    return {\"input_ids\": token_ids, \"attention_masks\": attention_masks}\n",
    "\n",
    "\n",
    "encoded_train = encode_dataset(tokenizer, train_reviews, 200)\n",
    "encoded_train[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_valid = encode_dataset(tokenizer, val_reviews, 200)\n",
    "encoded_test = encode_dataset(tokenizer, test_reviews, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFCamembertModel\n",
    "from tensorflow.keras.layers import Dropout, Dense, Activation\n",
    "\n",
    "\n",
    "class ClassificationModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, intent_num_labels=None, model_name=\"jplu/tf-camembert-base\",\n",
    "                 dropout_prob=0.1):\n",
    "        super().__init__(name=\"joint_intent_slot\")\n",
    "        self.bert = TFCamembertModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Classification head\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(dropout_prob)\n",
    "        #self.linear_1 = tf.keras.layers.Dense(768)\n",
    "        #self.activation = tf.keras.layers.Activation('tanh')\n",
    "        #self.dropout_2 = tf.keras.layers.Dropout(dropout_prob)\n",
    "        self.linear_2 = tf.keras.layers.Dense(2)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        sequence_output, pooled_output = self.bert(inputs, **kwargs)\n",
    "\n",
    "        x = self.dropout_1(pooled_output, training=kwargs.get(\"training\", False))        \n",
    "        #x = self.linear_1(x)\n",
    "        #x = self.activation(x)\n",
    "        #x = self.dropout_2(x, training=kwargs.get(\"training\", False))\n",
    "        logits = self.linear_2(x)\n",
    "        return logits\n",
    "\n",
    "# TODO: see https://huggingface.co/transformers/v2.1.1/_modules/transformers/modeling_tf_roberta.html#TFRobertaForSequenceClassification\n",
    "intent_model = ClassificationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)    \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "\n",
    "intent_model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFCamembertForSequenceClassification\n",
    "\n",
    "model = TFCamembertForSequenceClassification.from_pretrained(\"jplu/tf-camembert-base\")\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)    \n",
    "\n",
    "model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_camembert_for_sequence_classification_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "roberta (TFRobertaMainLayer) multiple                  110621952 \n",
      "_________________________________________________________________\n",
      "classifier (TFRobertaClassif multiple                  592130    \n",
      "=================================================================\n",
      "Total params: 111,214,082\n",
      "Trainable params: 111,214,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_for_sequence_classification_4/roberta/pooler/dense/kernel:0', 'tf_camembert_for_sequence_classification_4/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_for_sequence_classification_4/roberta/pooler/dense/kernel:0', 'tf_camembert_for_sequence_classification_4/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "12000/12000 [==============================] - 569s 47ms/sample - loss: 0.2662 - accuracy: 0.8785 - val_loss: 0.1659 - val_accuracy: 0.9366\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 571s 48ms/sample - loss: 0.1176 - accuracy: 0.9565 - val_loss: 0.1431 - val_accuracy: 0.9489\n",
      "Epoch 3/10\n",
      " 1184/12000 [=>............................] - ETA: 7:47 - loss: 0.0858 - accuracy: 0.9707"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-7de3361d8584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(\n\u001b[1;32m      2\u001b[0m     \u001b[0mencoded_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Trained with max length = 200, val_accuracy = 0.9489 after 2 epochs\n",
    "history = model.fit(\n",
    "    encoded_train, y_train, epochs=10, batch_size=8, \n",
    "    validation_data=(encoded_valid, y_val), verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
