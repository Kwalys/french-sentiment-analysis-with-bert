{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# better display of review text in dataframes\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "\n",
    "# Seaborn options\n",
    "sns.set(style=\"whitegrid\", font_scale=1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "PICKLE_PATH = \"allocine_dataset/data/allocine_dataset.pickle\"\n",
    "\n",
    "with open(PICKLE_PATH, 'rb') as reader:\n",
    "    data = pickle.load(reader)\n",
    "\n",
    "# Reviews need to be tokenized\n",
    "train_reviews = np.array(data[\"train_set\"]['review'])\n",
    "val_reviews = np.array(data[\"val_set\"]['review'])\n",
    "test_reviews = np.array(data[\"test_set\"]['review'])\n",
    "all_reviews = np.concatenate((train_reviews, val_reviews, test_reviews), axis=0)\n",
    "\n",
    "y_train = np.array(data[\"train_set\"]['polarity'])\n",
    "y_val = np.array(data[\"val_set\"]['polarity'])\n",
    "y_test = np.array(data[\"test_set\"]['polarity'])\n",
    "class_names = data['class_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionnal (subset)\n",
    "train_reviews = train_reviews[:3000]\n",
    "val_reviews = val_reviews[:3000]\n",
    "y_train = y_train[:3000]\n",
    "y_val = y_val[:3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer\n",
    "\n",
    "model_name = \"camembert-base\"\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gros déception ! Je ne comprends pas pourquoi adapter un livre si pour ne pas en tenir compte. Le côté \"histoire\" n\\'est pas exploité, la fin n\\'a plus rien avoir avec le livre... Ils nous avaient déjà gâcher la fin d\\'anges & demons, mais la vraiment on se demande pourquoi cette adaptation. Fan du livre passez votre chemin'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_review = train_reviews[2]\n",
    "some_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Gros',\n",
       " '▁déception',\n",
       " '▁!',\n",
       " '▁Je',\n",
       " '▁ne',\n",
       " '▁comprends',\n",
       " '▁pas',\n",
       " '▁pourquoi',\n",
       " '▁adapter',\n",
       " '▁un',\n",
       " '▁livre',\n",
       " '▁si',\n",
       " '▁pour',\n",
       " '▁ne',\n",
       " '▁pas',\n",
       " '▁en',\n",
       " '▁tenir',\n",
       " '▁compte',\n",
       " '.',\n",
       " '▁Le',\n",
       " '▁côté',\n",
       " '▁\"',\n",
       " 'histoire',\n",
       " '\"',\n",
       " '▁n',\n",
       " \"'\",\n",
       " 'est',\n",
       " '▁pas',\n",
       " '▁exploité',\n",
       " ',',\n",
       " '▁la',\n",
       " '▁fin',\n",
       " '▁n',\n",
       " \"'\",\n",
       " 'a',\n",
       " '▁plus',\n",
       " '▁rien',\n",
       " '▁avoir',\n",
       " '▁avec',\n",
       " '▁le',\n",
       " '▁livre',\n",
       " '...',\n",
       " '▁Ils',\n",
       " '▁nous',\n",
       " '▁avaient',\n",
       " '▁déjà',\n",
       " '▁gâcher',\n",
       " '▁la',\n",
       " '▁fin',\n",
       " '▁d',\n",
       " \"'\",\n",
       " 'ange',\n",
       " 's',\n",
       " '▁&',\n",
       " '▁de',\n",
       " 'mons',\n",
       " ',',\n",
       " '▁mais',\n",
       " '▁la',\n",
       " '▁vraiment',\n",
       " '▁on',\n",
       " '▁se',\n",
       " '▁demande',\n",
       " '▁pourquoi',\n",
       " '▁cette',\n",
       " '▁adaptation',\n",
       " '.',\n",
       " '▁Fan',\n",
       " '▁du',\n",
       " '▁livre',\n",
       " '▁passez',\n",
       " '▁votre',\n",
       " '▁chemin']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(some_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 5507,\n",
       " 10480,\n",
       " 83,\n",
       " 100,\n",
       " 45,\n",
       " 4312,\n",
       " 34,\n",
       " 590,\n",
       " 9426,\n",
       " 23,\n",
       " 510,\n",
       " 86,\n",
       " 24,\n",
       " 45,\n",
       " 34,\n",
       " 22,\n",
       " 1852,\n",
       " 287,\n",
       " 9,\n",
       " 54,\n",
       " 423,\n",
       " 87,\n",
       " 549,\n",
       " 130,\n",
       " 49,\n",
       " 11,\n",
       " 41,\n",
       " 34,\n",
       " 15130,\n",
       " 7,\n",
       " 13,\n",
       " 259,\n",
       " 49,\n",
       " 11,\n",
       " 55,\n",
       " 40,\n",
       " 254,\n",
       " 190,\n",
       " 42,\n",
       " 16,\n",
       " 510,\n",
       " 57,\n",
       " 436,\n",
       " 63,\n",
       " 917,\n",
       " 235,\n",
       " 24064,\n",
       " 13,\n",
       " 259,\n",
       " 18,\n",
       " 11,\n",
       " 4104,\n",
       " 10,\n",
       " 537,\n",
       " 8,\n",
       " 13990,\n",
       " 7,\n",
       " 65,\n",
       " 13,\n",
       " 302,\n",
       " 91,\n",
       " 48,\n",
       " 400,\n",
       " 590,\n",
       " 78,\n",
       " 7696,\n",
       " 9,\n",
       " 10772,\n",
       " 25,\n",
       " 510,\n",
       " 9797,\n",
       " 75,\n",
       " 1111,\n",
       " 6]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(some_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Gros déception! Je ne comprends pas pourquoi adapter un livre si pour ne pas en tenir compte. Le côté \"histoire\" n\\'est pas exploité, la fin n\\'a plus rien avoir avec le livre... Ils nous avaient déjà gâcher la fin d\\'anges & demons, mais la vraiment on se demande pourquoi cette adaptation. Fan du livre passez votre chemin</s>'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(some_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_sequence_lengths = [len(tokenizer.encode(text, max_length=512))\n",
    "                          for text in train_reviews]\n",
    "plt.hist(train_sequence_lengths, bins=30)\n",
    "plt.title(f\"max sequence length: {max(train_sequence_lengths)}\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32005"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_val = tf.keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    5,    87,   243, ...,     0,     0,     0],\n",
       "       [    5,  5897,    49, ...,     0,     0,     0],\n",
       "       [    5,  5507, 10480, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [    5,  5326,  2534, ...,     0,     0,     0],\n",
       "       [    5,  5897,     8, ...,     0,     0,     0],\n",
       "       [    5,   746,   221, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode_dataset(tokenizer, text_sequences, max_length):\n",
    "    token_ids = np.zeros(shape=(len(text_sequences), max_length),\n",
    "                         dtype=np.int32)\n",
    "    for i, text_sequence in enumerate(text_sequences):\n",
    "        encoded = tokenizer.encode(text_sequence, max_length=max_length)\n",
    "        token_ids[i, 0:len(encoded)] = encoded\n",
    "    attention_masks = (token_ids != 0).astype(np.int32)\n",
    "    return {\"input_ids\": token_ids, \"attention_masks\": attention_masks}\n",
    "\n",
    "\n",
    "encoded_train = encode_dataset(tokenizer, train_reviews, 512)\n",
    "encoded_train[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_valid = encode_dataset(tokenizer, val_reviews, 512)\n",
    "encoded_test = encode_dataset(tokenizer, test_reviews, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFCamembertModel\n",
    "from tensorflow.keras.layers import Dropout, Dense, Activation\n",
    "\n",
    "\n",
    "class ClassificationModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, intent_num_labels=None, model_name=\"jplu/tf-camembert-base\",\n",
    "                 dropout_prob=0.1):\n",
    "        super().__init__(name=\"joint_intent_slot\")\n",
    "        self.bert = TFCamembertModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Classification head\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(dropout_prob)\n",
    "        #self.linear_1 = tf.keras.layers.Dense(768)\n",
    "        #self.activation = tf.keras.layers.Activation('tanh')\n",
    "        #self.dropout_2 = tf.keras.layers.Dropout(dropout_prob)\n",
    "        self.linear_2 = tf.keras.layers.Dense(2)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        sequence_output, pooled_output = self.bert(inputs, **kwargs)\n",
    "\n",
    "        x = self.dropout_1(pooled_output, training=kwargs.get(\"training\", False))        \n",
    "        #x = self.linear_1(x)\n",
    "        #x = self.activation(x)\n",
    "        #x = self.dropout_2(x, training=kwargs.get(\"training\", False))\n",
    "        logits = self.linear_2(x)\n",
    "        return logits\n",
    "\n",
    "# TODO: see https://huggingface.co/transformers/v2.1.1/_modules/transformers/modeling_tf_roberta.html#TFRobertaForSequenceClassification\n",
    "intent_model = ClassificationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)    \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "\n",
    "intent_model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFCamembertForSequenceClassification\n",
    "\n",
    "model = TFCamembertForSequenceClassification.from_pretrained(\"jplu/tf-camembert-base\")\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)    \n",
    "\n",
    "model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_for_sequence_classification_4/roberta/pooler/dense/kernel:0', 'tf_camembert_for_sequence_classification_4/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_for_sequence_classification_4/roberta/pooler/dense/kernel:0', 'tf_camembert_for_sequence_classification_4/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "12000/12000 [==============================] - 569s 47ms/sample - loss: 0.2662 - accuracy: 0.8785 - val_loss: 0.1659 - val_accuracy: 0.9366\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 571s 48ms/sample - loss: 0.1176 - accuracy: 0.9565 - val_loss: 0.1431 - val_accuracy: 0.9489\n",
      "Epoch 3/10\n",
      " 1184/12000 [=>............................] - ETA: 7:47 - loss: 0.0858 - accuracy: 0.9707"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-7de3361d8584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(\n\u001b[1;32m      2\u001b[0m     \u001b[0mencoded_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Trained with max length = 200, val_accuracy = 0.9489 after 2 epochs\n",
    "history = model.fit(\n",
    "    encoded_train, y_train, epochs=10, batch_size=8, \n",
    "    validation_data=(encoded_valid, y_val), verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 4000 samples\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_camembert_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "12000/12000 [==============================] - 1634s 136ms/sample - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "12000/12000 [==============================] - 1631s 136ms/sample - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6969 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "12000/12000 [==============================] - 1635s 136ms/sample - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6967 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "12000/12000 [==============================] - 1637s 136ms/sample - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "12000/12000 [==============================] - 1638s 137ms/sample - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "12000/12000 [==============================] - 1638s 136ms/sample - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "12000/12000 [==============================] - 1638s 136ms/sample - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "12000/12000 [==============================] - 1637s 136ms/sample - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "12000/12000 [==============================] - 1637s 136ms/sample - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "12000/12000 [==============================] - 1636s 136ms/sample - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "10185/12000 [========================>.....] - ETA: 3:43 - loss: 0.6932 - accuracy: 0.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-741e4ae6e0f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(\n\u001b[1;32m      2\u001b[0m     \u001b[0mencoded_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/french_sentiment_analysis_with_bert-quJAe4Xa/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    encoded_train, y_train, epochs=30, batch_size=3, \n",
    "    validation_data=(encoded_valid, y_val), verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
